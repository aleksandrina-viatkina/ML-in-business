{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-father",
   "metadata": {},
   "source": [
    "### Машинное обучение в бизнесе\n",
    "### КУРСОВОЙ ПРОЕКТ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-administration",
   "metadata": {},
   "source": [
    "**Описание датасета**:    \n",
    "\n",
    "Датасет взят из kaggle - https://www.kaggle.com/blackmoon/russian-language-toxic-comments  \n",
    "Даны токсичные комментарии на русском языке - хорошие \"нетоксичные\" и токсичные.  \n",
    "Датасет содержит всего 2 столбца - комментарий и метка токсичности.  \n",
    "  \n",
    "  \n",
    "**Задача** - определить токсичность комментария  \n",
    "  \n",
    "Базовый класс - 0 (хороший, \"нетоксичный\" комментарий)  \n",
    "Целевой класс - 1 (плохой, токсичный комметарий)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "patient-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "leading-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask-ngrok\n",
    "#!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "equal-wichita",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aleksandrinavatkina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aleksandrinavatkina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#для обработки текста\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from razdel import tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import pymorphy2  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#для построения pipeline\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#для построения модели\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#для интерпретации результатов модели\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import urllib\n",
    "\n",
    "import pickle, dill, json\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import Flask, request, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "miniature-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "quantitative-julian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment     object\n",
       "toxic      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-dressing",
   "metadata": {},
   "source": [
    "#### Изучим целевую переменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "above-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "#скорректируем тип целевой переменной\n",
    "df['toxic'] = df['toxic'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "received-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.66514\n",
       "1    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-relaxation",
   "metadata": {},
   "source": [
    "Выраженный дисбаланс классов, хорошие комментарии явно преобладают над токсичными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-tobacco",
   "metadata": {},
   "source": [
    "#### Разобьем датасет на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "legitimate-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['comment'], df['toxic'], test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "charming-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv')\n",
    "X_test.to_csv('X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "flying-drive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.663362\n",
       "1    0.336638\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "biological-excuse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.669288\n",
       "1    0.330712\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-vitamin",
   "metadata": {},
   "source": [
    "Баланс классов в тренировочной и тестовой выборке примерно совпадает."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-assurance",
   "metadata": {},
   "source": [
    "#### Feature Engineering  \n",
    "\n",
    "Датасет крайне небольшой - всего 2 колонки, поэтому основной задачей будет обработка текста. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "productive-motor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Игромания не переходит к Канобу, никоим образом. Гаджи - новый сотрудник, руководитель, но не владелец и не главред. И да, он создал Канобу и был его операционным директором, но не является им в настоящий момент. Нет никакой речи о пересечении между этими двумя площадками.\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Попробуем произвести обработку на одном примере\n",
    "comment_example = X_train.iloc[1]\n",
    "comment_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "copyrighted-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "#токены\n",
    "tokens = word_tokenize(comment_example, language=\"russian\")\n",
    "\n",
    "#токены без пунктуации\n",
    "tokens_without_punctuation = [i for i in tokens if i not in string.punctuation]\n",
    "\n",
    "#загрузим стоп слова из русского языка\n",
    "russian_stop_words = stopwords.words(\"russian\")\n",
    "\n",
    "# выведем токены без стоп слов и без знаков препинания\n",
    "tokens_without_stop_words_and_punctuation = [i for i in tokens_without_punctuation if i not in russian_stop_words]\n",
    "\n",
    "#Проведем стемматизацию - \"отрежем\" окончания и суффиксы, оставим только корень слова \n",
    "snowball = SnowballStemmer(language=\"russian\")\n",
    "stemmed_tokens = [snowball.stem(i) for i in tokens_without_stop_words_and_punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "difficult-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Игромания не переходит к Канобу, никоим образом. Гаджи - новый сотрудник, руководитель, но не владелец и не главред. И да, он создал Канобу и был его операционным директором, но не является им в настоящий момент. Нет никакой речи о пересечении между этими двумя площадками.\n",
      "\n",
      "Токены: ['Игромания', 'не', 'переходит', 'к', 'Канобу', ',', 'никоим', 'образом', '.', 'Гаджи', '-', 'новый', 'сотрудник', ',', 'руководитель', ',', 'но', 'не', 'владелец', 'и', 'не', 'главред', '.', 'И', 'да', ',', 'он', 'создал', 'Канобу', 'и', 'был', 'его', 'операционным', 'директором', ',', 'но', 'не', 'является', 'им', 'в', 'настоящий', 'момент', '.', 'Нет', 'никакой', 'речи', 'о', 'пересечении', 'между', 'этими', 'двумя', 'площадками', '.'] \n",
      "\n",
      "Токены без пунктуации: ['Игромания', 'не', 'переходит', 'к', 'Канобу', 'никоим', 'образом', 'Гаджи', 'новый', 'сотрудник', 'руководитель', 'но', 'не', 'владелец', 'и', 'не', 'главред', 'И', 'да', 'он', 'создал', 'Канобу', 'и', 'был', 'его', 'операционным', 'директором', 'но', 'не', 'является', 'им', 'в', 'настоящий', 'момент', 'Нет', 'никакой', 'речи', 'о', 'пересечении', 'между', 'этими', 'двумя', 'площадками'] Токены без пунктуации и стоп слов: ['Игромания', 'переходит', 'Канобу', 'никоим', 'образом', 'Гаджи', 'новый', 'сотрудник', 'руководитель', 'владелец', 'главред', 'И', 'создал', 'Канобу', 'операционным', 'директором', 'является', 'настоящий', 'момент', 'Нет', 'никакой', 'речи', 'пересечении', 'этими', 'двумя', 'площадками']\n",
      "\n",
      "Токены после стемминга: ['игроман', 'переход', 'каноб', 'нико', 'образ', 'гадж', 'нов', 'сотрудник', 'руководител', 'владелец', 'главред', 'и', 'созда', 'каноб', 'операцион', 'директор', 'явля', 'настоя', 'момент', 'нет', 'никак', 'реч', 'пересечен', 'эт', 'двум', 'площадк']\n"
     ]
    }
   ],
   "source": [
    "# выведем результат на примере одного комментария, чтобы понять, корректно ли произведена обработка\n",
    "\n",
    "print(f\"Исходный текст: {comment_example}\\nТокены: {tokens} \\n\\nТокены без пунктуации: {tokens_without_punctuation} \\\n",
    "Токены без пунктуации и стоп слов: {tokens_without_stop_words_and_punctuation}\\n\\n\\\n",
    "Токены после стемминга: {stemmed_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "flush-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию для обработки текста на основе протестированной обработки выше:\n",
    "\n",
    "#для стемминга\n",
    "snowball = SnowballStemmer(language=\"russian\")\n",
    "\n",
    "#загрузим русские стоп слова\n",
    "russian_stop_words = stopwords.words(\"russian\")\n",
    "\n",
    "def tokenize_comment(comment: str, remove_stop_words: bool = True):\n",
    "    tokens = word_tokenize(comment, language=\"russian\")\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    if remove_stop_words:\n",
    "        tokens = [i for i in tokens if i not in russian_stop_words]\n",
    "    tokens = [snowball.stem(i) for i in tokens]\n",
    "    return tokens\n",
    "\n",
    "#[SnowballStemmer(language=\"russian\").stem(i) for i in word_tokenize(x, language=\"russian\") \\\n",
    "#                if i not in string.punctuation and if i not in stopwords.words(\"russian\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "engaging-bracelet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['игроман',\n",
       " 'переход',\n",
       " 'каноб',\n",
       " 'нико',\n",
       " 'образ',\n",
       " 'гадж',\n",
       " 'нов',\n",
       " 'сотрудник',\n",
       " 'руководител',\n",
       " 'владелец',\n",
       " 'главред',\n",
       " 'и',\n",
       " 'созда',\n",
       " 'каноб',\n",
       " 'операцион',\n",
       " 'директор',\n",
       " 'явля',\n",
       " 'настоя',\n",
       " 'момент',\n",
       " 'нет',\n",
       " 'никак',\n",
       " 'реч',\n",
       " 'пересечен',\n",
       " 'эт',\n",
       " 'двум',\n",
       " 'площадк']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим как будет работать на нашем выбранном примере\n",
    "tokenize_comment(comment_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-ordinary",
   "metadata": {},
   "source": [
    "Отлично, функция работает корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "parental-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['привет', 'дел']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Соберем эту фунцию в генератор\n",
    "[SnowballStemmer(language=\"russian\").stem(i) for i in word_tokenize('Привет как дела', language=\"russian\") if (i not in string.punctuation and i not in stopwords.words(\"russian\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "breathing-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим TFIDF Vetorizer  с использованием написанной выше функцией\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: [SnowballStemmer(language=\"russian\").stem(i) for i in word_tokenize(x, language=\"russian\") if (i not in string.punctuation and i not in stopwords.words(\"russian\"))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-bosnia",
   "metadata": {},
   "source": [
    "#### Соберем PIPELINE и обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "differential-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "#СОБЕРЕМ PIPELINE\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',TfidfVectorizer(tokenizer=lambda x: [SnowballStemmer(language=\"russian\").stem(i) for i in word_tokenize(x, language=\"russian\") if (i not in string.punctuation and i not in stopwords.words(\"russian\"))])),\n",
    "    ('model', LogisticRegression(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "exciting-couple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function <lambda> at 0x7fc2303b3430>)),\n",
       "                ('model', LogisticRegression(random_state=0))])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучим pipeline\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "lined-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем предсказание\n",
    "\n",
    "y_predict = pipeline.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "recent-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.359030, F-Score=0.817, Precision=0.775, Recall=0.864\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, y_predict)\n",
    "\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# выделим индекс с наибольшим значением fscore\n",
    "ix = np.argmax(fscore)\n",
    "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
    "                                                                        fscore[ix],\n",
    "                                                                        precision[ix],\n",
    "                                                                        recall[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-weather",
   "metadata": {},
   "source": [
    "Отлично, получили вполне хороший результат    \n",
    "Помимо текущей модели, были протестированы \"деревянные\" ансамблевые модели - GradientBoosting и RandomForest, но даже с подбором гиперпараметров модели дали результат слабее, нежели Логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-orlando",
   "metadata": {},
   "source": [
    "**Потестируем случайные придуманные комментарии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "regular-spyware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['Привет как дела'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "promising-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(['Я пошел в магазин'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "conservative-puppy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344556618226281"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-favorite",
   "metadata": {},
   "source": [
    "#### Сохраним модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "hired-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"logreg_pipeline_.dill\", \"wb\") as f:\n",
    "    dill.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-relief",
   "metadata": {},
   "source": [
    "**Сохраним версионирование** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "familiar-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "versioning = {'date': '15.10.2021',\n",
    "              'model': 'logreg_pipeline_.dill',\n",
    "              'version': '1.0.0'\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bearing-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"versioning.dill\", \"wb\") as f:\n",
    "    dill.dump(versioning, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-athletics",
   "metadata": {},
   "source": [
    "#### Создадим образ и контейнер Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "olive-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-symposium",
   "metadata": {},
   "source": [
    "список образов - docker images -a    \n",
    "удаление образа - docker rmi Image Image  \n",
    "список контейнеров - docker ps -a  \n",
    "удаление контейнера - docker rm ID_or_Name ID_or_Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "turkish-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd course_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "potential-library",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Создаем образ\n",
    "#!docker build -t classification_comments ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-reducing",
   "metadata": {},
   "source": [
    "**Собираем контейнер**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "composite-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! docker run -d -p 8183:8183 -v /Users/aleksandrinavatkina/Desktop/GeekBrains/'Машинное обучение в бизнесе'/les9_cp/course_project/app/models:/app/app/models classification_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-track",
   "metadata": {},
   "source": [
    "Сохраним id контейнера - 0780eb3bc34879dbf2b16e95eaa6ef825b6c58be055de3ee432c812c09904a9f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-diamond",
   "metadata": {},
   "source": [
    "Готово! Собрали наш контейнер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-synthesis",
   "metadata": {},
   "source": [
    "**Проверяем работу и делаем предсказания**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "apparent-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('/Users/aleksandrinavatkina/Desktop/GeekBrains/Машинное обучение в бизнесе/les9_cp/X_test.csv', index_col = 0, header=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "straight-equality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11824    А в районах победнее под ногами можно найти на...\n",
       "5594                Весь мир Прям смешно стало, свинявый\\n\n",
       "135                           пруф или пи..бол шарлатан)\\n\n",
       "12046    Меня после жизни в СПб уже не пугают такие цен...\n",
       "13038    Я тоже начал собирать пивные крышки, но только...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим как выглядит файл\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "finite-environment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "isolated-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(comment):\n",
    "    body = {'comment': [comment]} \n",
    "    myurl = \"http://172.20.10.3:8183/classify\" #наш url\n",
    "    req = urllib.request.Request(myurl)\n",
    "    req.add_header('Content-Type', 'application/json; charset=utf-8')\n",
    "    jsondata = json.dumps(body)\n",
    "    jsondataasbytes = jsondata.encode('utf-8')   # needs to be bytes\n",
    "    req.add_header('Content-Length', len(jsondataasbytes))\n",
    "    #print (jsondataasbytes)\n",
    "    response = urllib.request.urlopen(req, jsondataasbytes)\n",
    "    return json.loads(response.read())['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "intermediate-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(\"Жопа\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "worth-matrix",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction('Я пошел в магазин. Спишемся позже')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "productive-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11824    0\n",
       "5594     0\n",
       "135      0\n",
       "12046    0\n",
       "13038    0\n",
       "13076    0\n",
       "4468     0\n",
       "7565     1\n",
       "12203    1\n",
       "6235     1\n",
       "11526    0\n",
       "4641     0\n",
       "153      0\n",
       "9531     0\n",
       "13638    1\n",
       "5831     1\n",
       "1160     1\n",
       "6922     0\n",
       "9729     0\n",
       "9314     0\n",
       "3669     0\n",
       "10073    0\n",
       "5722     0\n",
       "3773     0\n",
       "9420     0\n",
       "9288     0\n",
       "12900    0\n",
       "7137     0\n",
       "4930     0\n",
       "8854     0\n",
       "12033    0\n",
       "11498    0\n",
       "8900     0\n",
       "7682     1\n",
       "8155     1\n",
       "11402    0\n",
       "9309     0\n",
       "3144     0\n",
       "8076     0\n",
       "4913     0\n",
       "6596     0\n",
       "1217     0\n",
       "8792     0\n",
       "8395     0\n",
       "10817    0\n",
       "5222     0\n",
       "6126     0\n",
       "1949     0\n",
       "8096     0\n",
       "13714    0\n",
       "Name: comment, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = X_test.iloc[:50].apply(lambda x: get_prediction(x))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-praise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-observer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
